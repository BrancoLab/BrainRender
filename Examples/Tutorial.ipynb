{"cells":[{"cell_type":"markdown","metadata":{},"outputs":[],"source":["# BrainRender Tutorial"]},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["In this tutorial you will be shown the main functionalities of BrainRender, but if you want to dive deeper into the various options available you can check out the other examples!"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"# We begin by adding the current path to sys.path to make sure that the imports work correctly\nimport sys\nsys.path.append('../')\nimport os\n\n# Set up VTKPLOTTER to work in Jupyter notebooks\nfrom vtkplotter import *\nembedWindow(backend=False) \n\n# Import variables\nfrom BrainRender.variables import * # <- these can be changed to personalize the look of your renders"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Brain render allows for the creation of a \"scene\" in which to render a number of 3d objects (e.g. brain structures, neurons reconstructions etc.)\nso we first need to import the class Scene and create an instance of it, then we can add objects (\"actors\") to it. \n\n"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"from BrainRender.scene import Scene"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"### Rendering brain regions\nTo add brain regions to our scene, we can use the \"add_brain_regions\" function. \nTo spicy which brain regions to render, we pass a list of strings, each of which is the acronym that corresponds to the brain region of interest.\n\nWhen you're rendering a brain region for the first time, BrainRender will download the corresponding .obj file from the Allen API and stores it in the Data folder. Note: this requires an internet connection."},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"# Let's create our first scene!\ntutorial_scene = Scene(jupyter=True)"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"tutorial_scene.add_brain_regions(['MOs', 'MOp'], colors='red') # Add brain regions to the scene\n"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# This will render the scene in a new window. \n# Press 'Esc' to close it.\ntutorial_scene.render()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"To know which brain structures are supported and what their acronyms here, you can print the list\nof available structures:"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"tutorial_scene.print_structures()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# we can also render multiple brain regions and only color the ones we are interested:\n# create a new scene\ntutorial_scene = Scene(jupyter=True)\n# display multiple regions and color the \"VIP\" regions\ntutorial_scene.add_brain_regions(['CA1', 'ZI', 'MOs'], colors='green', VIP_regions=['MOs'], VIP_color='red') \ntutorial_scene.render()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"# Rendering neurons\nBrainRender let's you render neurons reconstructed by the Mouse Light project from Janelia. \nIf you have already downloaded neurons data from the Neurons Browser, go ahead and use the .json or .swc files you've got directly in BrainRender. Otherwise, BrainRender also let's you download the data directly (see Neurons example).\n\nYou can find a couple example files in \"Examples/example_files\" to get you started,\n"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"# Get the filepath of the JSON file\nneurons_file = \"Examples/example_files/one_neuron.json\"\n\n# Get the Mouse Light data loader function\nfrom BrainRender.Utils.parsers.mouselight import NeuronsParser"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"When rendering neurons you have many options to choose how to color them. For more detailes check out the example on Neurons."},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# Create the actors for the neurons to render\ntutorial_scene = Scene(jupyter=True)\nparser = NeuronsParser(scene=tutorial_scene, \n                            color_neurites=True, axon_color=\"antiquewhite\", \n                            soma_color=\"darkgoldenrod\", dendrites_color=\"firebrick\")\nneurons, _ = parser.render_neurons(neurons_file)\n"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# then use the \"add_neurons\" function  to add the neurons to the scene (and don't forget to render it!)\ntutorial_scene.add_neurons(neurons)\ntutorial_scene.render()"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# And you can show neurons and brain structures in the same scene to get a better understanding of where these beautiful axons go:\ntutorial_scene = Scene(jupyter=True)\ntutorial_scene.add_neurons(neurons)\ntutorial_scene.add_brain_regions(['ZI'], colors='white', alpha=0.5) # add the ZonaIncerta to our scene\ntutorial_scene.render()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"### Rendering connectivity data\nBrainRender can be used to render tractography data downloaded from the Allen Brain Atlas mouse Connectome Database.\nThese data show afferent projections to a point of interest. \nGiven a brain region of interest, we can download data from experiments whose injections showed projections to our brain region. Then we can render these projections in 3D"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"# This kind of interctions with the Allen Brain Atlas datasets are handled by the class called ABA\nfrom BrainRender.Utils.ABA.connectome import ABA\nanalyzer = ABA()\ntutorial_scene = Scene(jupyter=True)\n"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"# Get the projections to the Zona Incerta\n# First, get a point within the zona incerta\np0 = tutorial_scene.get_region_CenterOfMass(\"ZI\")\n# Then, use these coordinates to fetch tractography data\ntract = analyzer.get_projection_tracts_to_target(p0=p0) # <- this might take a few seconds."},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"# create a new scene. Add the projections, the mesh for the ZI and render the scene. \ntutorial_scene.add_brain_regions(['ZI'], colors='red', alpha=.5) # add the PAG to our scene\ntutorial_scene.add_tractography(tract, display_injection_structure=False, color_by=\"region\")\ntutorial_scene.render()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Don't forget to check the other examples to lear more about how to use BrainRender to make amazing 3D renderings!\nAlso, you can find a list of variables you can play around with in BrainRender.variables.py\nPlaying around with these variables will allow you to make the rendering look exactly how you want them to be."}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}